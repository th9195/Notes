[TOC]



# 1- rdd转DataFrame/DataSet

<span style="color:red;background:white;font-size:20px;font-family:楷体;">**import spark.implicits._**</span>

``` scala
println("---------- 通过样例类 构建 DF ----------")
val rdd = sc.textFile("data/input/person.txt").map(line => {
    val arr = line.split(" ")
    MyPerson(arr(0).toInt, arr(1), arr(2).toInt)
})
import spark.implicits._
val df1 = rdd.toDF
df1.printSchema()
df1.show()
```



## 2- DSL 编程中使用select方法使用 col方法时

<span style="color:red;background:white;font-size:20px;font-family:楷体;">**import org.apache.spark.sql.functions._**</span>

``` scala
import org.apache.spark.sql.functions._
val dsl5 = df.select(col("name"))
dsl5.show()
```



## 3- DSL编程中使用agg包含多个聚合函数时

<span style="color:red;background:white;font-size:20px;font-family:楷体;">**import  org.apache.spark.sql.functions._**</span>

``` scala
import  org.apache.spark.sql.functions._
        df.groupBy($"movieID")
                .agg(
                    count("userID").as("cnt"),
                    round(avg($"rating"),2).as("avg_rating")
                ).filter($"cnt" > 200)
                .select($"movieID",$"avg_rating")
                .orderBy($"avg_rating".desc)
                .limit(10).show()
```

